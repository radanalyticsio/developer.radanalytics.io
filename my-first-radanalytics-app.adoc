= SparkPi: an introduction to applications using Apache Spark with radanalytics.io
:page-link: my-first-radanalytics-app
:page-layout: markdown
:page-menu_entry: My First App
:page-description: In this tutorial you will learn how to create a source-to-image application for Apache Spark from the ground up. The source code is based on the upstream Pi calculator from the Apache Spark project examples with a slight twist, the addition of a web server to create an on-demand calculation microservice.

pass:[<h1>SparkPi: an introduction to applications using Apache Spark with radanalytics.io</h1>]

In this tutorial you will build a microservice which will calculate an
approximate value for https://en.wikipedia.org/wiki/Pi[Pi] when requested by
HTTP. You will learn how to create applications that utilize Apache Spark and
that are deployed directly from a source repository to OpenShift with a single command.

This tutorial walks you through the steps of creating, deploying and operating
an Apache Spark driver application on OpenShift. You should expect to spend
30 to 60 minutes on these exercises.

[[prerequisites]]
== Prerequisites

* You have access to an OpenShift cluster.
* A terminal with the `oc` command is available.
* A new project in OpenShift is available to store your work.
* The Oshinko templates are available in your project (See the
  link:/howdoi/install-radanalyticsio[How do I install radanalytics.io?]
  article for instructions.)
* An editor to work on your source files is available.
* An online space for a Git repository is available to store your code, such
  as https://github.com[GitHub], https://bitbucket.com[BitBucket] or
  https://gitlab.com[GitLab].

[[overview]]
== Application overview

The SparkPi microservice that you will build during this tutorial is quite
simple in its design and functionality. SparkPi is deployed as a single server
pod and several Apache Spark pods. The microservice provides an HTTP server
that accepts `GET` requests and responds with an estimation of Pi. It does
this by using Apache Spark to calculate the value by using the
https://en.wikipedia.org/wiki/Approximations_of_%CF%80#Summing_a_circle.27s_area[summing of a circle's area]
technique.

Note that usually you would not run extended calculations during an HTTP
request unless the calculations can be completed quickly. However, this
simplifies the implementation details. As you build further applications from
the material provided here, keep this simplification of design in mind.

Regardless of the implementation language or the HTTP framework, all of the
tutorial applications linked from this page have the same general
architecture. The following diagram shows the major components involved with
deployment and usage of the microservice:

pass:[<img src="/assets/my-first-radanalytics-app/sparkpi-architecture.svg" class="img-responsive center-block">]

**Component key**

1. Computer with a web browser or other method for making HTTP requests

2. The "SparkPi" microservice

3. An Apache Spark cluster

The SparkPi component is the main component that you will be concerned with
throughout the tutorial. You should already have a computer with the necessary
tools installed for making Pi requests, editing your source files and
commanding OpenShift to deploy your microservice. The Apache Spark cluster is
created automatically for you by the
http://github.com/radanalyticsio/oshinko-s2i[Oshinko source-to-image tools].

https://docs.openshift.org/latest/architecture/core_concepts/builds_and_image_streams.html#source-build[Source-to-image]
technology is fundamental to the operation of this tutorial. Source-to-image
provides a convenient way for you to produce container images directly from
your source repositories. This work is handled by language specific builder
images which can ingest your source code, assemble it and then produce an
application image which is ready to be deployed. In the case of the Oshinko
source-to-image builders, an Apache Spark cluster is also created dynamically
for your application when it runs.

[[setup]]
== Setup your coding environment

To use the source-to-image workflow you will need to have a
https://git-scm.com[Git] repository to store your work. This repository is
then used by the source-to-image builders to create the final application
image which will be run on OpenShift. For the purposes of this tutorial your
repository must be accessible by the OpenShift cluster. The easiest way to do
this is by using an external service like https://github.com[GitHub],
https://bitbucket.com[BitBucket], or https://gitlab.com[GitLab].

Create a new repository on your preferred platform and make a local clone of
it. For more information see
https://confluence.atlassian.com/get-started-with-bitbucket/create-a-repository-861178559.html[BitBucket's documentation]
and https://help.github.com/articles/create-a-repo/[GitHub's documentation].

With your freshly minted repository you are ready to start coding!

[[stack]]
== Choose your language and technology stack

This tutorial was developed for multiple languages and HTTP frameworks.
Functionally, all of these microservices work in the same manner with similar
results to an end user. In this way they represent a black box style
microservice which can be replaced with another component that satisfies the
same input and output requirements.

Each of these language specific tutorials provide instructions on how to
structure your repository and what files to create. You will also learn how
each microservice works and the commands necessary to build and launch them
in OpenShift. Because the source-to-image templates that you will use are
language specific, you must choose a single implementation to exist in your
repository. When you are finished, return here to learn about interacting
with your microservice and exposing it outside of OpenShift. Choose
one of the following language and framework options:

* link:/assets/my-first-radanalytics-app/sparkpi-java-spring.html[Java with Spring]
* link:/assets/my-first-radanalytics-app/sparkpi-java-vertx.html[Java with Vert.x]
* link:/assets/my-first-radanalytics-app/sparkpi-python-flask.html[Python with Flask]

[[user]]
== Become a user

At this point you should have created a code repository for your microservice,
populated the repository with source files, built an application image, and
launched that image on OpenShift. The final stage in this tutorial is to
expose your microservice outside of OpenShift and begin interacting with it as
a user.

The first step in this process is to expose a route to your microservice.
OpenShift contains an edge router which associates domain name URIs with
services. By default, applications you create through source-to-image have
services that can expose routes which will contain their name, the project
name and a hostname for the OpenShift server. You can create these routes by
using the following command:

....
oc expose svc/sparkpi
....

To see the routes available in your project, run `oc get routes`. This command
should return output similar to the following example:

....
$ oc get route
NAME                      HOST/PORT                                      PATH      SERVICES            PORT       TERMINATION   WILDCARD
cluster-uo7wa9-ui-route   cluster-uo7wa9-ui-route-pi.10.0.1.109.xip.io             cluster-uo7wa9-ui   <all>                    None
sparkpi                   sparkpi-pi.10.0.1.109.xip.io                             sparkpi             8080-tcp                 None
....

Notice that in addition to the `sparkpi` route you created earlier that there
is also a route prefixed with `cluster-`. This is the route created
automatically by the Oshinko source-to-image tooling and it provides access
to the Apache Spark web interface. You can visit either one of these routes
in your web browser to inspect the results.

In addition to accessing the SparkPi microservice through the web browser,
you can use the `curl` tool and command scripting to achieve the results. The
following commands substitute in the URI for your service and the results
should look similar for you:

....
$ curl http://`oc get routes/sparkpi --template='{{.spec.host}}'`
Python Flask SparkPi server running. Add the 'sparkpi' route to this URL to invoke the app.

$ curl http://`oc get routes/sparkpi --template='{{.spec.host}}'`/sparkpi
Pi is roughly 3.140480
....

You can see that this rough approximation is close, but not quite close
enough. Try adding the `scale` parameter to your URL to see how it affects the
outcome.

....
curl http://`oc get routes/sparkpi --template='{{.spec.host}}'`/sparkpi?scale=5
....

[[explore]]
== Continue exploring

You have created and deployed your first radanalytics.io application onto
OpenShift. At this point you are beginning to understand the core concepts
behind the Oshinko source-to-image tooling. Investigate the other applications
and examples in the link:/tutorials[Tutorials] section and also revisit the
link:/get-started[Get Started] page to learn how you can use the Oshinko WebUI
to control the Apache Spark clusters in your projects.
