= Teaching Apache Spark Clusters to Manage Their Workers Elastically
:page-presentor: Erik Erlandson, Trevor Mckay
:page-date: 2017-02-08
:page-media-url: https://youtu.be/vxALlQ2mTbI
:page-slides-url: http://www.slideshare.net/SparkSummit/teaching-apache-spark-clusters-to-manage-their-workers-elastically-spark-summit-east-talk-by-erik-erlandson-and-trevor-mckay

Devops engineers have applied a great deal of creativity and energy to invent tools that automate infrastructure management, in the service of deploying capable and functional applications. For data-driven applications running on Apache Spark, the details of instantiating and managing the backing Spark cluster can be a distraction from focusing on the application logic. In the spirit of devops, automating Spark cluster management tasks allows engineers to focus their attention on application code that provides value to end-users.

Using Openshift Origin as a laboratory, we implemented a platform where Apache Spark applications create their own clusters and then dynamically manage their own scale via host-platform APIs. This makes it possible to launch a fully elastic Spark application with little more than the click of a button.

We will present a live demo of turn-key deployment for elastic Apache Spark applications, and share what weâ€™ve learned about developing Spark applications that manage their own resources dynamically with platform APIs.

The audience for this talk will be anyone looking for ways to streamline their Apache Spark cluster management, reduce the workload for Spark application deployment, or create self-scaling elastic applications. Attendees can expect to learn about leveraging APIs in the Kubernetes ecosystem that enable application deployments to manipulate their own scale elastically.
